{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from single_split_gridsearch import SingleSplitGridSearch\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#10000\n",
    "n = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "1\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "2\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "3\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "4\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "videos_train = ['MVI_0788_VIS_OB', 'MVI_0789_VIS_OB', 'MVI_0792_VIS_OB', 'MVI_0794_VIS_OB', 'MVI_0796_VIS_OB']\n",
    "video_test = 'MVI_0804_VIS_OB'\n",
    "\n",
    "# Reads bank currency note data into pandas dataframe - TRAIN\n",
    "bankdata_train = pd.read_csv(\"../METEP/Features/\" + videos_train[0] + \"R_frame0.csv\")\n",
    "\n",
    "for i in range (5):\n",
    "    k = 0\n",
    "    print(i)\n",
    "    if i == 0:\n",
    "        k = 20\n",
    "    while k < 299:\n",
    "        print(k)\n",
    "        bankdata_train = bankdata_train.append(pd.read_csv(\"../METEP/Features/\" + videos_train[i] + \"R_frame\" + str(k) + \".csv\"))\n",
    "        k += 20\n",
    "        if videos_train[i] == 'MVI_0789_VIS_OB' and k == 280:\n",
    "            k = 400\n",
    "\n",
    "# Show number of lines and columns\n",
    "#bankdata.shape\n",
    "# Show a able wih some lines of he daa\n",
    "#bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "# Reads bank currency note data into pandas dataframe - TEST\n",
    "\n",
    "bankdata_test = pd.read_csv(\"../METEP/Features/\" + video_test + \"R_frame0.csv\")\n",
    "\n",
    "k = 20\n",
    "while k < 299:\n",
    "    print(k)\n",
    "    bankdata_test = bankdata_test.append(pd.read_csv(\"../METEP/Features/\" + video_test + \"R_frame\" + str(k) + \".csv\"))\n",
    "    k += 20\n",
    "    if video_test == 'MVI_0789_VIS_OB' and k == 280:\n",
    "            k = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into attributes and labels\n",
    "\n",
    "# Store attributes\n",
    "X_train = bankdata_train.drop('class', axis=1)\n",
    "# Store labels\n",
    "Y_train = bankdata_train['class']\n",
    "\n",
    "# Store attributes\n",
    "X_test = bankdata_test.drop('class', axis=1)\n",
    "# Store labels\n",
    "Y_test = bankdata_test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando as bases\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "c:\\users\\thais\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1676: RuntimeWarning: init_size=300 should be larger than k=5000. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "mask_Sky = Y_train == 1\n",
    "mask_NonSky = Y_train == 0\n",
    "\n",
    "km = MiniBatchKMeans(\n",
    "    n_clusters=n, init='k-means++',\n",
    "    n_init=10, max_iter=300, \n",
    "    tol=1e-04\n",
    ")\n",
    "\n",
    "Sky_km = km.fit(X_train[mask_Sky])\n",
    "sky = km.cluster_centers_\n",
    "\n",
    "NonSky_km = km.fit(X_train[mask_NonSky])\n",
    "nonsky = km.cluster_centers_\n",
    "\n",
    "features = np.concatenate([sky, nonsky])\n",
    "\n",
    "class_Sky = np.ones((n), dtype=np.int8)\n",
    "class_NonSky = np.zeros((n), dtype=np.int8)\n",
    "\n",
    "classes = np.concatenate([class_Sky, class_NonSky])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "### SingleSplitGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done  16 out of  16 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores parametros encontrados: {'C': 1000, 'gamma': 0.2}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88   1340072\n",
      "           1       0.02      0.68      0.04      9928\n",
      "\n",
      "    accuracy                           0.78   1350000\n",
      "   macro avg       0.51      0.73      0.46   1350000\n",
      "weighted avg       0.99      0.78      0.87   1350000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71070631, 0.28929369])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inicializar uma instância da SVM. Os parametros que não forem alterados durante\n",
    "#o grid search permanecem os mesmos em todos os modelos avaliados.\n",
    "#Por exemplo, todos os modelos avaliados terão probability=True\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "#Indicar quais parametros serão avaliados na busca exaustiva (GridSearch)\n",
    "Cs = [1, 10, 100, 1000]\n",
    "gammas = [2e-3, 2e-2, 2e-1, 'auto']\n",
    "\n",
    "#Param_grid é um dicionário que associa o nome dos parametros passados para criação do classificador\n",
    "#(parametros passados para o SVC, por exemplo) a lista de parametros a serem avaliados.\n",
    "param_grid={\n",
    "    'C' : Cs,\n",
    "    'gamma' : gammas\n",
    "}\n",
    "\n",
    "#Configurar a busca exaustiva. Note que é passado um parametro test_size, que indica a proporção do conjunto\n",
    "#de treino que será usado para validação. Neste caso, 20% dos dados de treino passados para o método fit\n",
    "#serão usados como validação. Além disto, esta separação é feita de forma estratificada, tentando manter\n",
    "#a mesma proporção de dados no treino e na validação de acordo com cada classe.\n",
    "#n_jobs permite que cada modelo seja treinado em paralelo, neste caso, n_jobs=4 permite que 4\n",
    "#modelos sejam treinados em paralelo. verbose=10 indica que serão mostradas informações sobre a execução\n",
    "#do treino. Caso não queira estas informações, basta atribuir verbose=0.\n",
    "model = SingleSplitGridSearch(svm, param_grid, n_jobs=2, verbose=10, test_size=0.2)\n",
    "\n",
    "#Fazer a busca exaustiva. Ao final, model será retreinado com a melhor combinação de parametros obtida, usando\n",
    "#todos os dados de treino.\n",
    "model.fit(features, classes)\n",
    "\n",
    "#Por curiosidade, mostrar os melhores parametros encontrados\n",
    "print()\n",
    "print(\"Melhores parametros encontrados: \" + str(model.best_params_))\n",
    "print()\n",
    "\n",
    "#O método predict está disponível\n",
    "predicted = model.predict(X_test)\n",
    "print(classification_report(Y_test, predicted))\n",
    "\n",
    "#E o predict_proba tbm...\n",
    "model.predict_proba(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
