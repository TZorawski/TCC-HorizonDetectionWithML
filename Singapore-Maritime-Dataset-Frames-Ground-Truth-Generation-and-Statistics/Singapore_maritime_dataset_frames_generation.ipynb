{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore maritime dataset frames generation\n",
    "a\n",
    "\n",
    "a\n",
    "\n",
    "a\n",
    "\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the videos paths for both onboard and onshore data and generate dictionaries with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths for the video files and ground truth files\n",
    "\n",
    "\"\"\"\n",
    "VIDEOS_PATH_ONSHORE = \"../../Dataset/VIS_Onshore/Videos\"\n",
    "HORIZON_ANNOTATIONS_ONSHORE_PATH = \"../../Dataset/VIS_Onshore/HorizonGT\"\n",
    "VIDEO_FRAMES_PATH_ONSHORE = '../../Dataset/VIS_Onshore_frames/'\n",
    "\"\"\"\n",
    "\n",
    "VIDEOS_PATH_ONBOARD = \"../../Dataset/VIS_Onboard/Videos\"\n",
    "HORIZON_ANNOTATIONS_ONBOARD_PATH = \"../../Dataset/VIS_Onboard/HorizonGT\"\n",
    "VIDEO_FRAMES_PATH_ONBOARD = '../../Dataset/VIS_Onboard/VIS_Onboard_frames/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_files_onshore = [join(VIDEOS_PATH_ONSHORE, f) for f in listdir(VIDEOS_PATH_ONSHORE) \n",
    "#                        if isfile(join(VIDEOS_PATH_ONSHORE, f))]\n",
    "\n",
    "video_files_onboard = [join(VIDEOS_PATH_ONBOARD, f) for f in listdir(VIDEOS_PATH_ONBOARD) \n",
    "                       if isfile(join(VIDEOS_PATH_ONBOARD, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries for each video in the form video_name:video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "video_files_onshore_dict = {}\n",
    "for f in listdir(VIDEOS_PATH_ONSHORE):\n",
    "    if isfile(join(VIDEOS_PATH_ONSHORE, f)):\n",
    "        video_files_onshore_dict[f.split('.')[0]] = join(VIDEOS_PATH_ONSHORE, f)\n",
    "\"\"\"        \n",
    "video_files_onboard_dict = {}\n",
    "for f in listdir(VIDEOS_PATH_ONBOARD):\n",
    "    if isfile(join(VIDEOS_PATH_ONBOARD, f)):\n",
    "        video_files_onboard_dict[f.split('.')[0]] = join(VIDEOS_PATH_ONBOARD, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ground truth files paths for both onboard and onshore data and generate dictionaries with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "horizon_gt_files_onshore_dict = {}\n",
    "for f in listdir(HORIZON_ANNOTATIONS_ONSHORE_PATH):\n",
    "    if isfile(join(HORIZON_ANNOTATIONS_ONSHORE_PATH, f)):\n",
    "        horizon_gt_files_onshore_dict[f.split('.')[0].replace('_HorizonGT','')] = join(HORIZON_ANNOTATIONS_ONSHORE_PATH, f)\n",
    "\"\"\"        \n",
    "horizon_gt_files_onboard_dict = {}\n",
    "for f in listdir(HORIZON_ANNOTATIONS_ONBOARD_PATH):\n",
    "    if isfile(join(HORIZON_ANNOTATIONS_ONBOARD_PATH, f)):\n",
    "        horizon_gt_files_onboard_dict[f.split('.')[0].replace('_HorizonGT','')] = join(HORIZON_ANNOTATIONS_ONBOARD_PATH, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "\n",
    "## Do some checks\n",
    "\n",
    "#### Numbers of videos and ground truth files\n",
    "\n",
    "Do some sanity checks to see if there are equal numbers of videos and ground truth files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of onboard videos:  11\n",
      "Number of onboard ground truth files:  11\n"
     ]
    }
   ],
   "source": [
    "# print('Number of onshore videos: ', len(video_files_onshore_dict))\n",
    "# print('Number of onshore ground truth files: ', len(horizon_gt_files_onshore_dict))\n",
    "\n",
    "print('Number of onboard videos: ', len(video_files_onboard_dict))\n",
    "print('Number of onboard ground truth files: ', len(horizon_gt_files_onboard_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are videos without ground truth files and ground truth files without videos. These unlabelled data might be good for testing later. Let's find these videos and ground truth files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabelled onboard videos:  []\n",
      "\n",
      "Size of video dictionaries after removing the videos without ground truth:\n",
      "Number of onboard videos:  11\n",
      "Number of onboard ground truth files:  11\n"
     ]
    }
   ],
   "source": [
    "# ground truth files are missing - find the corresponding videos\n",
    "# videos are missing - find the corresponding ground truth files\n",
    "\"\"\"\n",
    "missing_files_onshore = []\n",
    "for key in video_files_onshore_dict.keys():\n",
    "    if key not in horizon_gt_files_onshore_dict:\n",
    "        missing_files_onshore.append(key)\n",
    "        \n",
    "for key in horizon_gt_files_onshore_dict.keys():\n",
    "    if key not in video_files_onshore_dict:\n",
    "        missing_files_onshore.append(key)\n",
    "        \n",
    "print(\"Unlabelled onshore videos: \", missing_files_onshore)\n",
    "\"\"\"\n",
    "\n",
    "missing_files_onboard = []\n",
    "for key in video_files_onboard_dict.keys():\n",
    "    if key not in horizon_gt_files_onboard_dict:\n",
    "        missing_files_onboard.append(key)\n",
    "        \n",
    "for key in horizon_gt_files_onboard_dict.keys():\n",
    "    if key not in video_files_onboard_dict:\n",
    "        missing_files_onboard.append(key)\n",
    "\n",
    "print(\"Unlabelled onboard videos: \", missing_files_onboard)\n",
    "\n",
    "\n",
    "# set whether to remove or not the missing videos from the frames generation later\n",
    "remove_missing_files = True\n",
    "if remove_missing_files:\n",
    "    #for key in missing_files_onshore:\n",
    "    #    del video_files_onshore_dict[key]\n",
    "    #    del horizon_gt_files_onshore_dict[key]\n",
    "    for key in missing_files_onboard:\n",
    "        del video_files_onboard_dict[key]\n",
    "        del horizon_gt_files_onboard_dict[key]\n",
    "\n",
    "    print()\n",
    "    print('Size of video dictionaries after removing the videos without ground truth:')\n",
    "    \"\"\"\n",
    "    print('Number of onshore videos: ', len(video_files_onshore_dict))\n",
    "    print('Number of onshore ground truth files: ', len(horizon_gt_files_onshore_dict))\n",
    "    \"\"\"\n",
    "\n",
    "    print('Number of onboard videos: ', len(video_files_onboard_dict))\n",
    "    print('Number of onboard ground truth files: ', len(horizon_gt_files_onboard_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Count video frame number and GT data frame number\n",
    "\n",
    "Do some sanity checks to see if there are equal numbers of videos and ground truth files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames MVI_0788_VIS_OB : 299\n",
      "Total frames MVI_0789_VIS_OB : 279\n",
      "Total frames MVI_0790_VIS_OB : 600\n",
      "Total frames MVI_0792_VIS_OB : 299\n",
      "Total frames MVI_0794_VIS_OB : 299\n",
      "Total frames MVI_0795_VIS_OB : 255\n",
      "Total frames MVI_0796_VIS_OB : 299\n",
      "Total frames MVI_0797_VIS_OB : 600\n",
      "Total frames MVI_0799_VIS_OB : 600\n",
      "Total frames MVI_0801_VIS_OB : 600\n",
      "Total frames MVI_0804_VIS_OB : 299\n"
     ]
    }
   ],
   "source": [
    "# count video frames\n",
    "for video_key in video_files_onboard_dict:\n",
    "    vidcap = cv2.VideoCapture(video_files_onboard_dict.get(video_key))\n",
    "\n",
    "    # get total frames of video\n",
    "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total frames \" + video_key + \" : \" + str(total_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GT frames MVI_0788_VIS_OB : 299\n",
      "Total GT frames MVI_0789_VIS_OB : 279\n",
      "Total GT frames MVI_0790_VIS_OB : 299\n",
      "Total GT frames MVI_0792_VIS_OB : 299\n",
      "Total GT frames MVI_0794_VIS_OB : 299\n",
      "Total GT frames MVI_0795_VIS_OB : 299\n",
      "Total GT frames MVI_0796_VIS_OB : 299\n",
      "Total GT frames MVI_0797_VIS_OB : 299\n",
      "Total GT frames MVI_0799_VIS_OB : 299\n",
      "Total GT frames MVI_0801_VIS_OB : 299\n",
      "Total GT frames MVI_0804_VIS_OB : 299\n"
     ]
    }
   ],
   "source": [
    "# count GT data frames\n",
    "for horizon_key in horizon_gt_files_onboard_dict:\n",
    "    # read GT data\n",
    "    data = loadmat(horizon_gt_files_onboard_dict.get(horizon_key))\n",
    "    \n",
    "    # get total frames of GT data\n",
    "    total_frames = len(data['structXML'][0])\n",
    "    print(\"Total GT frames \" + horizon_key + \" : \" + str(total_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of video dictionaries after removing the videos with different numbers of frames and ground truth:\n",
      "Number of onboard videos:  6\n",
      "Number of onboard ground truth files:  6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keys = list(horizon_gt_files_onboard_dict.keys())\n",
    "\n",
    "for key in keys:\n",
    "    #print(video_files_onboard_dict.get(video_keys[i]) + \" : \" + horizon_gt_files_onboard_dict.get(horizon_keys[i]))\n",
    "    \n",
    "    # read GT data\n",
    "    data = loadmat(horizon_gt_files_onboard_dict.get(key))\n",
    "    # get total frames of GT data\n",
    "    total_frames_gt = len(data['structXML'][0])\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(video_files_onboard_dict.get(key))\n",
    "    # get total frames of video\n",
    "    total_frames_video = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    #print(\"* \" + str(total_frames_gt) + \" - \" + str(total_frames_video))\n",
    "    if total_frames_gt != total_frames_video:\n",
    "        del video_files_onboard_dict[key]\n",
    "        del horizon_gt_files_onboard_dict[key]\n",
    "\n",
    "print()\n",
    "print('Size of video dictionaries after removing the videos with different numbers of frames and ground truth:')\n",
    "\n",
    "print('Number of onboard videos: ', len(video_files_onboard_dict))\n",
    "print('Number of onboard ground truth files: ', len(horizon_gt_files_onboard_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['MVI_0788_VIS_OB', 'MVI_0789_VIS_OB', 'MVI_0792_VIS_OB', 'MVI_0794_VIS_OB', 'MVI_0796_VIS_OB', 'MVI_0804_VIS_OB'])\n"
     ]
    }
   ],
   "source": [
    "print(video_files_onboard_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "\n",
    "## Convert ALL frames of the videos into jpg images\n",
    " This is code to convert each video frame into a jpg image.\n",
    "\n",
    "#### Example\n",
    " This cell is for converting only one video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a sample onshore video\n",
    "\n",
    "video_name = 'MVI_1478_VIS'\n",
    "vidcap = cv2.VideoCapture(video_files_onshore_dict.get(video_name))\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "  cv2.imwrite(VIDEO_FRAMES_PATH_ONSHORE + video_name + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "  success,image = vidcap.read()\n",
    "  #print('Read a new frame: ', success)\n",
    "  count += 1\n",
    "print(\"Derived %d frames\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a sample onboard video\n",
    "\n",
    "video_name = 'MVI_0788_VIS_OB'\n",
    "vidcap = cv2.VideoCapture(video_files_onboard_dict.get(video_name))\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "  cv2.imwrite(VIDEO_FRAMES_PATH_ONBOARD + video_name + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "  success,image = vidcap.read()\n",
    "  #print('Read a new frame: ', success)\n",
    "  count += 1\n",
    "print(\"Derived %d frames\" % count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert ALL frames\n",
    "\n",
    "This cell is for converting all the videos in a folder into jpg images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ALL on shore videos into images with 1 image per frame\n",
    "for video_key in video_files_onshore_dict:\n",
    "    #video_name = 'MVI_1478_VIS'\n",
    "    vidcap = cv2.VideoCapture(video_files_onshore_dict.get(video_key))\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "      cv2.imwrite(VIDEO_FRAMES_PATH_ONSHORE + video_key + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "      success,image = vidcap.read()\n",
    "      #print('Read a new frame: ', success)\n",
    "      count += 1\n",
    "    print(\"Derived %d frames\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ALL on board videos into images with 1 image per frame\n",
    "for video_key in video_files_onboard_dict:\n",
    "    #video_name = 'MVI_1478_VIS'\n",
    "    vidcap = cv2.VideoCapture(video_files_onboard_dict.get(video_key))\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "      cv2.imwrite(VIDEO_FRAMES_PATH_ONBOARD + video_key + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "      success,image = vidcap.read()\n",
    "      #print('Read a new frame: ', success)\n",
    "      count += 1\n",
    "    print(\"Derived %d frames\" % count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "## Convert every N frame of a video into jpg image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert every N onshore videos into images with 1 image per frame\n",
    "for video_key in video_files_onshore_dict:\n",
    "    frame_space = 20\n",
    "    vidcap = cv2.VideoCapture(video_files_onshore_dict.get(video_key))\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        if (count == 0) or ((count+1) % frame_space == 0):\n",
    "            cv2.imwrite(VIDEO_FRAMES_PATH_ONSHORE + video_key + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "            frame_count += 1\n",
    "        success,image = vidcap.read()\n",
    "        #print('Read a new frame: ', success)\n",
    "        count += 1\n",
    "    print(video_key)\n",
    "    print(\"Total %d frames\" % count)\n",
    "    print(\"Derived %d frames\" % frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVI_0788_VIS_OB\n",
      "Total 299 frames\n",
      "Derived 15 frames\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-856ceee15308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVIDEO_FRAMES_PATH_ONBOARD\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvideo_key\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_frame%d.jpg\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# save frame as JPEG file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mframe_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;31m#print('Read a new frame: ', success)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# convert every N onboard videos into images with 1 image per frame\n",
    "for video_key in video_files_onboard_dict:\n",
    "    frame_space = 20\n",
    "    vidcap = cv2.VideoCapture(video_files_onboard_dict.get(video_key))\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        if (count == 0) or ((count+1) % frame_space == 0):\n",
    "            cv2.imwrite(VIDEO_FRAMES_PATH_ONBOARD + video_key + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "            frame_count += 1\n",
    "        success,image = vidcap.read()\n",
    "        #print('Read a new frame: ', success)\n",
    "        count += 1\n",
    "    print(video_key)\n",
    "    print(\"Total %d frames\" % count)\n",
    "    print(\"Derived %d frames\" % frame_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "Fazer: redimensionar imagens\n",
    "Fazer: arrmar ocave ara gerar caracerisicas com mariz\n",
    "Fazer: gerar lo de linha real com nova ecnologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
